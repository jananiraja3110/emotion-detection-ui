# ğŸ­ Multimodal Emotion Detection System Using Deep Learning

This project is a **modern AI-based web application** that detects human emotions from:

- ğŸ¥ **Video** (facial expressions)
- ğŸ§ **Audio** (voice tone)
- âœï¸ **Text** (sentiment & emotion words)
- ğŸ”€ **Fusion** (combines all three for higher accuracy)

It uses **Deep Learning models** (TensorFlow/Keras) for emotion classification and is built with a clean, interactive **Flask web interface**.  
Users can upload media or input text, and the system returns emotion predictions such as **Happy**, **Sad**, **Angry**, **Neutral**, etc.

---

## ğŸ’¡ Project Explanation

### ğŸ§  Goal
To build an AI system that can **detect human emotions** using input from:

- ğŸ¥ Facial expressions (video)
- ğŸ§ Voice tone (audio)
- âœï¸ Written text (text)
- ğŸ”€ Fusion (all combined)

Each input is analyzed using deep learning models, and the result is shown via a **modern web UI**.

---

## ğŸ“˜ Project Workflow Overview

### 1. **User Interface (HTML/CSS - Flask `templates/index.html`)**
- Users upload files (video/audio) or type text
- UI is modern, responsive, and interactive

### 2. **Backend (Flask - Python)**
- Flask routes handle each modality separately (`/`, `/audio`, `/text`, `/fusion`)
- Uploaded data is saved temporarily and passed to respective emotion detection functions

### 3. **Model Inference**
- Deep learning models (stored as `.h5`) are used for:
  - Video: Face detection + CNN classification
  - Audio: MFCC feature extraction + classifier
  - Text: Tokenization + LSTM/CNN/NLP model
- Output: Emotion like *Happy*, *Sad*, *Angry*, *Neutral*

### 4. **Fusion Logic**
- Combines results from all three modalities and gives final prediction (e.g., majority voting or weighted decision)

---

## ğŸ”§ Technologies Used

| Layer       | Tools/Tech                             |
|-------------|----------------------------------------|
| ğŸ‘©â€ğŸ’» Backend | Python, Flask                          |
| ğŸ§  AI/ML     | TensorFlow, Keras, OpenCV, librosa     |
| ğŸ–¼ï¸ UI        | HTML5, CSS3, Responsive Layout         |
| ğŸ¨ Theme     | Soft Modern UI (Poppins, Hover effects)|

---

## ğŸ“š Libraries Used & Their Purpose

### ğŸ§  Machine Learning / Deep Learning
| Library        | Purpose |
|----------------|---------|
| `TensorFlow` / `Keras` | Load trained deep learning models (`.h5`), predict emotion |
| `OpenCV` (`cv2`) | Process video frames, detect face, draw emotion labels |
| `librosa` | Extract audio features (like MFCC) for emotion prediction |
| `numpy` | Numerical computations (arrays, matrices) |
| `sklearn` | Optional: preprocessing, metrics, model evaluation |

### ğŸŒ Web Application
| Library | Purpose |
|---------|---------|
| `Flask` | Main backend framework â€“ handle routes, user inputs, serve pages |
| `Werkzeug` | Handle file uploads securely (via `request.files`) |
| `Jinja2` | Templating system used inside HTML for dynamic values |

### ğŸ–¼ï¸ UI & Frontend
| Tool      | Purpose |
|-----------|---------|
| `HTML/CSS` | Build and style the frontend layout |
| `Google Fonts` | Custom fonts (like `Poppins`) for modern look |
| `Emoji Icons` | Make the interface fun and emotionally expressive |
| `CSS Transitions` | Hover effects, scaling cards, smooth animations |

---

## ğŸš€ Features

- ğŸ¥ Upload a **video** to detect facial emotion frame-by-frame  
- ğŸ§ Upload an **audio file** to extract emotion from voice tone  
- âœï¸ Type or paste **text** to analyze sentiment using NLP  
- ğŸ”€ Run **Fusion Detection** by combining video, audio, and text  
- ğŸ–¼ï¸ Displays the processed video with emotion labels  
- ğŸ’« Soft UI, animated cards, and a responsive interface

---

## ğŸ“¦ How to Run Locally


# 1. Clone the repo
git clone https://github.com/jananiraja3110/emotion-detection-ui.git
cd emotion-detection-ui

# 2. (Optional) Create virtual environment
python -m venv env
env\Scripts\activate      # on Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the application
python app.py
```

ğŸ”— Open browser at: [http://localhost:5000](http://localhost:5000)

---

## ğŸ‘©â€ğŸ’» About the Author

**Janani R**  
AI & Deep Learning Enthusiast  
ğŸŒ [GitHub](https://github.com/jananiraja3110)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/jananiraja3110)

---

## ğŸ“Œ Status

âœ… Emotion detection working for all modalities  
ğŸ”„ More visualizations and charts coming soon  
ğŸ“¬ Suggestions & contributions welcome!
