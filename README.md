# ğŸ­ Multimodal Emotion Detection System Using Deep Learning

This project is a **modern AI-based web application** that detects human emotions from:

- ğŸ¥ **Video** (facial expressions)
- ğŸ§ **Audio** (voice tone)
- âœï¸ **Text** (sentiment & emotion words)
- ğŸ”€ **Fusion** (combines all three for higher accuracy)

It uses **Deep Learning models** (TensorFlow/Keras) for emotion classification and is built with a clean, interactive **Flask web interface**.  
Users can upload media or input text, and the system returns emotion predictions such as **Happy**, **Sad**, **Angry**, **Neutral**, etc.

---

## ğŸ”§ Technologies Used

| Layer       | Tools/Tech                              |
|-------------|----------------------------------------  |
| ğŸ‘©â€ğŸ’» Backend | Python, Flask                            |
| ğŸ§  AI/ML     | TensorFlow, Keras, OpenCV, librosa     |
| ğŸ–¼ï¸ UI        | HTML5, CSS3, Responsive Layout         |
| ğŸ¨ Theme     | Soft Modern UI (Poppins, Hover effects)|

---

## ğŸš€ Features

- ğŸ¥ Upload a **video** to detect facial emotion frame-by-frame  
- ğŸ§ Upload an **audio file** to extract emotion from voice tone  
- âœï¸ Type or paste **text** to analyze sentiment using NLP  
- ğŸ”€ Run **Fusion Detection** by combining video, audio, and text  
- ğŸ–¼ï¸ Displays the processed video with emotion labels  
- ğŸ’« Soft UI, animated cards, and a responsive interface

---

## ğŸ“¦ How to Run Locally


# 1. Clone the repo
git clone https://github.com/jananiraja3110/emotion-detection-ui.git
cd emotion-detection-ui

# 2. (Optional) Create virtual environment
python -m venv env
env\Scripts\activate      # on Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the application
python app.py
